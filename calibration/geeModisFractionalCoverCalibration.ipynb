{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Earth Engine to build a MODIS fractional cover calibration\n",
    "====================================================================\n",
    "This is based on [Scarth *etal*](https://dx.doi.org/10.6084/m9.figshare.94250) endmember extraction method.\n",
    "The basic process is to:\n",
    "\n",
    " 1. Assemble the field site data\n",
    " 2. Extract the reflectannce data from the closest pixel in space and time\n",
    " 3. Calculate the satellite viewed cover amount from the field data\n",
    " 4. Compute the best fitting image endmembers based on the field and image data sets\n",
    " 5. Use these endmembers to unmix the Earth Engine imagery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.core.display import Image\n",
    "import os, numpy, plotly, time, datetime\n",
    "from scipy.linalg import pinv2, svd\n",
    "from scipy.optimize import nnls\n",
    "import ee\n",
    "\n",
    "\n",
    "# Initialise Plotly first time by running:\n",
    "# python -c \"import plotly; plotly.tools.set_credentials_file(username='xxxxxx', api_key='yyyyy')\"\n",
    "\n",
    "# Initialize the Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "# Connect to the field site fusion table.\n",
    "fieldSites = ee.FeatureCollection('ft:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "# Have a look at the data structure using:\n",
    "# print fieldSites.getInfo()['features'][1]\n",
    "\n",
    "# Import MODIS Imagery\n",
    "mcd43a4 = ee.ImageCollection('MODIS/MCD43A4')\n",
    "\n",
    "# Get the latest image\n",
    "latestImage = mcd43a4.sort('system:time_start', False ).limit(1).median()\n",
    "# Have a look at the data structure using: print(latestImage.getInfo())\n",
    "bufferedSites = fieldSites.map(lambda site:site.buffer(10000))\n",
    "siteImage = latestImage.select('Nadir_Reflectance_Band6', 'Nadir_Reflectance_Band2', 'Nadir_Reflectance_Band1').paint(bufferedSites,10000)\n",
    "\n",
    "#Get a bounding region for the thumbnail extract\n",
    "coords = fieldSites.geometry().convexHull().buffer(200000).getInfo()['coordinates']\n",
    "# Produce an image thumbnail\n",
    "imageURL = siteImage.getThumbUrl({'region': coords,'format': 'png','min':100,'max': 5000,'dimensions': '400'})\n",
    "# Display the image    \n",
    "Image(url=imageURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the MODIS reflectance data from the Earth Engine by selecting the points nearest in space and time\n",
    "------------------------------------------------------------------\n",
    "\n",
    "Here we have to consider:\n",
    "\n",
    " - The presence of nans\n",
    " - The possibility of a few dates close to the\n",
    "   field data\n",
    " - The adjustment of the field data to model what the\n",
    "   satellite views\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract point data from imagery close in time\n",
    "def pixelDataAtPoint(imageCollection,javascriptTimestamp,coordinates):\n",
    "    # Convert to datetime object\n",
    "    nominalDate = datetime.datetime.fromtimestamp(javascriptTimestamp/1000)\n",
    "    # Buffer by 10 days\n",
    "    sampleDaysRange = datetime.timedelta(days=10)\n",
    "    # Start date \n",
    "    startDate = nominalDate - sampleDaysRange\n",
    "    # End date\n",
    "    endDate = nominalDate + sampleDaysRange\n",
    "    # Select the relevant images\n",
    "    extractCollection = ee.ImageCollection(imageCollection).filterDate(startDate, endDate);\n",
    "    # Get the pixel value at a scale of 100m\n",
    "    pointExtracted = extractCollection.getRegion(ee.Geometry.Point(coordinates[0],coordinates[1]),100)\n",
    "    # create an image from the collection\n",
    "    return pointExtracted.getInfo()\n",
    "\n",
    "# Function that takes a getRegion list and computes the median of the reflectance data\n",
    "def pixelListToMean(pointData):\n",
    "    # List 0 is the band names\n",
    "    #print pointData[0]\n",
    "    pixelList = pointData[1:]\n",
    "    # Convert to float\n",
    "    pixelArray = numpy.ndarray.astype(numpy.array(pointData[1:])[:,4:],dtype=float)\n",
    "    # Return the median\n",
    "    try:\n",
    "        arrayMedian = numpy.nanmedian(pixelArray,axis=0)\n",
    "    except:\n",
    "        arrayMedian = numpy.zeros_like(pixelArray[0])\n",
    "    \n",
    "    return arrayMedian\n",
    "\n",
    "\n",
    "# Function to compute the fractional covers as viewed by the satellite for the site\n",
    "# Required a site properties object\n",
    "def fractionalCoverSatView(siteProperties):\n",
    "    nTotal = siteProperties['num_points']\n",
    "    # Canopy Layer\n",
    "    nCanopyBranch = siteProperties['over_b'] * nTotal / 100.0\n",
    "    nCanopyDead = siteProperties['over_d'] * nTotal / 100.0\n",
    "    nCanopyGreen = siteProperties['over_g'] * nTotal / 100.0\n",
    "    # Midstory Layer\n",
    "    nMidBranch = siteProperties['mid_b'] * nTotal / 100.0\n",
    "    nMidGreen = siteProperties['mid_g'] * nTotal / 100.0\n",
    "    nMidDead = siteProperties['mid_d'] * nTotal / 100.0\n",
    "    # Ground Layer\n",
    "    nGroundDeadLitter = (siteProperties['dead'] + siteProperties['litter']) * nTotal / 100.0\n",
    "    nGroundCrustDistRock = (siteProperties['crust'] + siteProperties['dist'] + siteProperties['rock']) * nTotal / 100.0\n",
    "    nGroundGreen = siteProperties['green'] * nTotal / 100.0\n",
    "    nGroundCrypto = siteProperties['crypto'] * nTotal / 100.0\n",
    "    # Work out the canopy elements as viewed from above\n",
    "    canopyFoliageProjectiveCover = nCanopyGreen / (nTotal - nCanopyBranch)\n",
    "    canopyDeadProjectiveCover = nCanopyDead / (nTotal - nCanopyBranch)\n",
    "    canopyBranchProjectiveCover = nCanopyBranch / nTotal * (1.0 - canopyFoliageProjectiveCover - canopyDeadProjectiveCover)\n",
    "    canopyPlantProjectiveCover = (nCanopyGreen+nCanopyDead + nCanopyBranch) / nTotal\n",
    "    # Work out the midstorey fractions\n",
    "    midFoliageProjectiveCover = nMidGreen / nTotal\n",
    "    midDeadProjectiveCover = nMidDead / nTotal\n",
    "    midBranchProjectiveCover = nMidBranch / nTotal\n",
    "    midPlantProjectiveCover = (nMidGreen + nMidDead + nMidBranch) / nTotal\n",
    "    # Work out the midstorey  elements as viewed by the satellite using a gap fraction method\n",
    "    satMidFoliageProjectiveCover = midFoliageProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidDeadProjectiveCover = midDeadProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidBranchProjectiveCover = midBranchProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidPlantProjectiveCover = midPlantProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    # Work out the groundcover fractions as seen by the observer\n",
    "    groundPVCover = nGroundGreen / nTotal\n",
    "    groundNPVCover = nGroundDeadLitter / nTotal\n",
    "    groundBareCover = nGroundCrustDistRock / nTotal\n",
    "    groundCryptoCover = nGroundCrypto / nTotal\n",
    "    groundTotalCover = (nGroundGreen + nGroundDeadLitter + nGroundCrustDistRock) / nTotal\n",
    "    # Work out the ground cover propoetions as seen by the satellite\n",
    "    satGroundPVCover = groundPVCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundNPVCover = groundNPVCover * ( 1- midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundBareCover = groundBareCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundCryptoCover = groundCryptoCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundTotalCover = groundTotalCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    # Final total covers calculated using gap probabilities through all layers\n",
    "    totalPVCover = canopyFoliageProjectiveCover + satMidFoliageProjectiveCover + satGroundPVCover\n",
    "    totalNPVCover = canopyDeadProjectiveCover + canopyBranchProjectiveCover + satMidDeadProjectiveCover + satMidBranchProjectiveCover + satGroundNPVCover\n",
    "    totalBareCover = satGroundBareCover\n",
    "    totalCryptoCover = satGroundCryptoCover\n",
    "    \n",
    "    return numpy.array([totalPVCover,totalNPVCover,totalBareCover,totalCryptoCover])\n",
    "    \n",
    "\n",
    "   \n",
    "# Create an empty array\n",
    "fractionalCoverArray = numpy.array([])\n",
    "modisReflectanceArray = numpy.array([])\n",
    "\n",
    "# Extract the data for all the sites\n",
    "for site in fieldSites.getInfo()['features']:\n",
    "    #print site['properties']['site']\n",
    "    \n",
    "    \n",
    "    # Extract the reflectance data from the nearest images\n",
    "    coordinates = site['geometry']['coordinates']\n",
    "    obsTime = site['properties']['obs_time']\n",
    "    # Check if the data is within the MODIS era\n",
    "    if datetime.datetime.fromtimestamp(obsTime/1000)>datetime.datetime(2000, 1, 1, 0, 0):\n",
    "        \n",
    "        try:\n",
    "            # Wait for a bit to avoid hitting the EE quota limits\n",
    "            time.sleep(1.0)\n",
    "            sitePixelList =  pixelDataAtPoint(mcd43a4,obsTime,coordinates)\n",
    "        except:\n",
    "            # Try again after a longer break\n",
    "            time.sleep(60.0)\n",
    "            sitePixelList =  pixelDataAtPoint(mcd43a4,obsTime,coordinates)\n",
    "\n",
    "        meanReflectance = pixelListToMean(sitePixelList)\n",
    "        # Data Array contains the 7 reflectance bands\n",
    "        modisReflectanceArray = numpy.append(modisReflectanceArray,meanReflectance)\n",
    "\n",
    "\n",
    "        # Calculate the fractional cover as seen by the satellite\n",
    "        siteCover = fractionalCoverSatView(site['properties'])\n",
    "        # Data Array contains the 4 fractional cover values\n",
    "        fractionalCoverArray = numpy.append(fractionalCoverArray,siteCover)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and save the extracted data for further analysis\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape the arrays based on the 7 reflectance or 4 cover parameters\n",
    "modisReflectanceArray = numpy.reshape(modisReflectanceArray,(-1,7))\n",
    "fractionalCoverArray = numpy.reshape(fractionalCoverArray,(-1,4))\n",
    "# Remove NANs\n",
    "isGoodIDX = numpy.where(~numpy.isnan(xdata))\n",
    "modisReflectanceArray = modisReflectanceArray[isGoodIDX]\n",
    "fractionalCoverArray = fractionalCoverArray[isGoodIDX]\n",
    "# And save the extracted data for reuse\n",
    "numpy.savetxt('modisReflectanceArray.txt', modisReflectanceArray)\n",
    "numpy.savetxt('fractionalCoverArray.txt', fractionalCoverArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data\n",
    "----------------\n",
    "\n",
    "Now we've extracted from the earth engine, we can undertake some basic data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data in from this point to continue\n",
    "modisReflectanceArray = numpy.loadtxt('modisReflectanceArray.txt')\n",
    "fractionalCoverArray = numpy.loadtxt('fractionalCoverArray.txt')\n",
    "\n",
    "# Remove any nans\n",
    "goodData = ~numpy.isnan(modisReflectanceArray).any(axis=1)\n",
    "modisReflectanceArray=modisReflectanceArray[goodData]\n",
    "fractionalCoverArray=fractionalCoverArray[goodData]\n",
    "\n",
    "# Remove the sites which don't add up to 100% for one reason or another\n",
    "goodSites=fractionalCoverArray[:,0:3].sum(axis=1) > 0.95\n",
    "totalPVCover=fractionalCoverArray[goodSites,0]\n",
    "totalNPVCover=fractionalCoverArray[goodSites,1]\n",
    "totalBareCover=fractionalCoverArray[goodSites,2]\n",
    "totalCryptoCover=fractionalCoverArray[goodSites,3]\n",
    "\n",
    "# Put Cryptogram in NPV for now. Version 2 will put the crypto into the correct class based on reflectance\n",
    "totalNPVCover=totalNPVCover+totalCryptoCover\n",
    "satelliteReflectance=modisReflectanceArray[goodSites]\n",
    "satelliteReflectance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traditional red band vs. cover relationship\n",
    "----------------\n",
    "As used in arid environments for some time. Red reflectance sorrelates sort of with cover - works best locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Fit some data\n",
    "xdata = modisReflectanceArray[:,0] # Red band\n",
    "ydata = fractionalCoverArray[:,2] # Bare ground\n",
    "\n",
    "# Polynomial Fitting\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(xdata,ydata)\n",
    "print \"r squared = %f\" % r_value**2\n",
    "\n",
    "fitPolyFun = numpy.poly1d([slope,intercept])\n",
    "fitData = fitPolyFun(xdata)\n",
    "\n",
    "\n",
    "# Create a site trace\n",
    "traceSites = plotly.graph_objs.Scatter(\n",
    "    x = xdata,\n",
    "    y = ydata,\n",
    "    mode = 'markers',\n",
    "    name = 'Sites',\n",
    "    marker=dict(color='red',symbol='circle',opacity=0.5)\n",
    ")\n",
    "\n",
    "# Create a fit trace\n",
    "traceFit = plotly.graph_objs.Scatter(\n",
    "    x = xdata,\n",
    "    y = fitData,\n",
    "    mode = 'lines',\n",
    "    name = 'Fitted Line',\n",
    "    line = dict(color = ('rgb(22, 96, 167)'),width = 4)\n",
    ")\n",
    "\n",
    "data = [traceSites,traceFit]\n",
    "\n",
    "layout = plotly.graph_objs.Layout(\n",
    "    title='Modis Red Band vs Bare Ground',\n",
    "    xaxis=dict(\n",
    "        title='MODIS Reflectance',\n",
    "        ticklen=5,\n",
    "        zeroline=False,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Bare Ground',\n",
    "        ticklen=5,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "plotFig = plotly.graph_objs.Figure(data=data, layout=layout)\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "plotly.plotly.iplot(plotFig, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the range of cover values\n",
    "----------------\n",
    "Using a histogram of bare ground over all the sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [plotly.graph_objs.Histogram(x=fractionalCoverArray.sum(axis=1))]\n",
    "#data = [plotly.graph_objs.Histogram(x=fractionalCoverArray[:,2])]\n",
    "plotly.plotly.iplot(data, filename='fractionalSums-histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add interactive terms to model the nonlinearities in the cover to reflectance relationship\n",
    "------------------------------------------------------------------------\n",
    "This dramatically improves unmixing performance without having to resort to multiple endmember models\n",
    "But it requires good field data to guide the process\n",
    "We make sure we don't overfit in the next step by trimming the singular values we use in the inversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeTransform(band):\n",
    "    band2=band[3]\n",
    "    band3=band[0]\n",
    "    band4=band[1]\n",
    "    band5=band[4]\n",
    "    band6=band[5]\n",
    "    band7=band[6]\n",
    "    return numpy.array([band2*band3, band2*band4, band2*band5, band2*band6, band2*band7,\\\n",
    "       band2*numpy.log(band2), band2*numpy.log(band3), band2*numpy.log(band4),\\\n",
    "       band2*numpy.log(band5), band2*numpy.log(band6), band2*numpy.log(band7), band3*band4, band3*band5,\\\n",
    "       band3*band6, band3*band7, band3*numpy.log(band2), band3*numpy.log(band3), band3*numpy.log(band4),\\\n",
    "       band3*numpy.log(band5), band3*numpy.log(band6), band3*numpy.log(band7), band4*band5, band4*band6, band4*band7,\\\n",
    "       band4*numpy.log(band2), band4*numpy.log(band3), band4*numpy.log(band4),\\\n",
    "       band4*numpy.log(band5), band4*numpy.log(band6), band4*numpy.log(band7), band5*band6, band5*band7, band5*numpy.log(band2),\\\n",
    "       band5*numpy.log(band3), band5*numpy.log(band4), band5*numpy.log(band5),\\\n",
    "       band5*numpy.log(band6), band5*numpy.log(band7), band6*band7, \\\n",
    "       band6*numpy.log(band2), band6*numpy.log(band3),\\\n",
    "       band6*numpy.log(band4), band6*numpy.log(band5), band6*numpy.log(band6), band6*numpy.log(band7),\\\n",
    "       band7*numpy.log(band2), band7*numpy.log(band3),\\\n",
    "       band7*numpy.log(band4), band7*numpy.log(band5), band7*numpy.log(band6), band7*numpy.log(band7),\\\n",
    "       numpy.log(band2)*numpy.log(band3), numpy.log(band2)*numpy.log(band4), numpy.log(band2)*numpy.log(band5),\\\n",
    "       numpy.log(band2)*numpy.log(band6), numpy.log(band2)*numpy.log(band7), numpy.log(band3)*numpy.log(band4), numpy.log(band3)*numpy.log(band5),\\\n",
    "       numpy.log(band3)*numpy.log(band6), numpy.log(band3)*numpy.log(band7), numpy.log(band4)*numpy.log(band5), numpy.log(band4)*numpy.log(band6),\\\n",
    "       numpy.log(band5)*numpy.log(band6), numpy.log(band5)*numpy.log(band7), numpy.log(band6)*numpy.log(band7), band2, band3, band4, band5, band6, band7,\\\n",
    "       numpy.log(band2), numpy.log(band3), numpy.log(band4), numpy.log(band5), numpy.log(band6), numpy.log(band7)])\n",
    "                        \n",
    "\n",
    "\n",
    "# Do the transformation\n",
    "satelliteReflectanceTransformed=numpy.array(map(computeTransform,(satelliteReflectance+1)/10000))\n",
    "\n",
    "\n",
    "# Create a  plot of the Singular Values\n",
    "U,s,Vh = svd(satelliteReflectanceTransformed.transpose())\n",
    "\n",
    "trace0 = plotly.graph_objs.Scatter(\n",
    "    x = numpy.linspace(0, s.size-1),\n",
    "    y = s,\n",
    "    mode = 'lines',\n",
    "    name = 'Singular-Values',\n",
    "    line = dict(color = ('rgb(22, 96, 167)'),width = 4))\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "data = [trace0]\n",
    "plotly.plotly.iplot(data, filename='svd-plot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the optimal dimensionality for inversion by cross validation\n",
    "--------------------------------------------------------------------\n",
    "This takes some time - we select the optimal subspace using an exhaustive search with 2fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optimal number of SVs\n",
    "sum2oneWeight=numpy.array([0.3])\n",
    "crossvalidationAmount=10\n",
    "\n",
    "bareRMSerror=[]\n",
    "U,s,Vh = svd(satelliteReflectanceTransformed.transpose())\n",
    "toleranceSVs=s/s.max()\n",
    "\n",
    "siteDataArray=numpy.array([totalPVCover,totalNPVCover,totalBareCover])\n",
    "\n",
    "numberSites=satelliteReflectanceTransformed[:,0].size\n",
    "\n",
    "    \n",
    "for i in range(toleranceSVs.size -1):\n",
    "    bareRMSerrorArray=[]\n",
    "    for loop in range(1000):\n",
    "        \n",
    "        shuffleIndex=numpy.random.permutation(numberSites)\n",
    "        calibrationSites=shuffleIndex[0:numpy.floor(numberSites/crossvalidationAmount)]\n",
    "        validationSites=shuffleIndex[numpy.floor(numberSites/crossvalidationAmount)+1:]\n",
    "    \n",
    "    \n",
    "        endmembersWeighted=pinv2(numpy.dot(siteDataArray[:,calibrationSites],\\\n",
    "        pinv2(satelliteReflectanceTransformed[calibrationSites].transpose(),\\\n",
    "        rcond=toleranceSVs[i])))\n",
    "    \n",
    "        endmembersWeightedSum=numpy.append(endmembersWeighted,numpy.array([sum2oneWeight.repeat(endmembersWeighted[0].size)]),axis=0)\n",
    "        \n",
    "        def spectralUnmixing(spectra):\n",
    "            return nnls(endmembersWeightedSum,numpy.append(spectra,sum2oneWeight))[0]\n",
    "    \n",
    "        retrievedCoverFractions = numpy.apply_along_axis(spectralUnmixing,1,satelliteReflectanceTransformed[validationSites])\n",
    "        \n",
    "        rmsError=numpy.sqrt(((siteDataArray[:,validationSites].transpose()-retrievedCoverFractions)**2).mean(axis=0))\n",
    "\n",
    "\n",
    "        bareRMSerrorArray=numpy.append(bareRMSerrorArray,rmsError[2])\n",
    "        \n",
    "    bareRMSerror=numpy.append(bareRMSerror,bareRMSerrorArray.mean())\n",
    "    \n",
    "rcond =  toleranceSVs[bareRMSerror.argmin()]\n",
    "print \"rcond = %f \" % rcond\n",
    "\n",
    "# Create a Crossvalidation plot\n",
    "trace0 = plotly.graph_objs.Scatter(\n",
    "    x = numpy.linspace(0, bareRMSerror.size -1),\n",
    "    y = numpy.log(bareRMSerror),\n",
    "    mode = 'lines',\n",
    "    name = 'Fitted Line',\n",
    "    line = dict(color = ('rgb(22, 167, 96)'),width = 4))\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "data = [trace0]\n",
    "plotly.plotly.iplot(data, filename='crossval-plot')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the optimal sum to one coefficient for inversion\n",
    "--------------------------------------------------------------------\n",
    "We select the optimal sum to one value that minimised the RMSE of the unmixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best Sum To One\n",
    "rcond = 0.0001\n",
    "bareRMSerror=[]\n",
    "for i in range(100):\n",
    "    sum2oneWeight=numpy.array(i/200.0)\n",
    "    endmembersWeightedSum=numpy.append(endmembersWeighted,numpy.array([sum2oneWeight.repeat(endmembersWeighted[0].size)]),axis=0)\n",
    "    \n",
    "    \n",
    "    def spectralUnmixing(spectra):\n",
    "        return nnls(endmembersWeightedSum,numpy.append(spectra,sum2oneWeight))[0]\n",
    "    \n",
    "    retrievedCoverFractions = numpy.apply_along_axis(spectralUnmixing,1,satelliteReflectanceTransformed)\n",
    "    rmsError=numpy.sqrt(((numpy.array([totalPVCover,totalNPVCover,totalBareCover]).transpose()-retrievedCoverFractions)**2).mean(axis=0))\n",
    "    bareRMSerror=numpy.append(bareRMSerror,rmsError.mean())\n",
    "\n",
    "\n",
    "# Create a Crossvalidation plot\n",
    "trace0 = plotly.graph_objs.Scatter(\n",
    "    x = numpy.arange(100)/50.0,\n",
    "    y = bareRMSerror,\n",
    "    mode = 'lines',\n",
    "    name = 'Fitted Line',\n",
    "    line = dict(color = ('rgb(22, 167, 96)'),width = 4))\n",
    "\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "data = [trace0]\n",
    "layout = plotly.graph_objs.Layout(\n",
    "    title='RMSE vs Sum to 1 Unmixing Constraint',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    xaxis=dict(\n",
    "        title='Sum to 1 weight',\n",
    "        ticklen=5,\n",
    "        zeroline=False,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='RMSE (%)',\n",
    "        ticklen=5,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "plotFig = plotly.graph_objs.Figure(data=data, layout=layout)\n",
    "plotly.plotly.iplot(plotFig, filename='sum2one-plot')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute the final Unmixing RMSE and make a plot of the values \n",
    "--------------------------------------------------------------------\n",
    "Note there is still a fair bit of \"noise\" but a reasonable relationshp given the number of field sites and the scale mismatch between 500 x 500 mMODIS and the 100m x 100m field sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optimal Endmember Test\n",
    "\n",
    "sum2oneWeight=numpy.array([0.25])\n",
    "rcond = 0.0001\n",
    "\n",
    "endmembersWeighted=pinv2(numpy.dot(numpy.array([totalPVCover,totalNPVCover,totalBareCover]),pinv2(satelliteReflectanceTransformed.transpose(),rcond=rcond)))\n",
    "\n",
    "endmembersWeightedSum=numpy.append(endmembersWeighted,numpy.array([sum2oneWeight.repeat(endmembersWeighted[0].size)]),axis=0)\n",
    "\n",
    "def spectralUnmixing(spectra):\n",
    "    return nnls(endmembersWeightedSum,numpy.append(spectra,sum2oneWeight))[0]\n",
    "\n",
    "retrievedCoverFractions = numpy.apply_along_axis(spectralUnmixing,1,satelliteReflectanceTransformed)\n",
    "\n",
    "rmsError=numpy.sqrt(((numpy.array([totalPVCover,totalNPVCover,totalBareCover]).transpose()-retrievedCoverFractions)**2).mean(axis=0))\n",
    "print rmsError\n",
    "\n",
    "\n",
    "\n",
    "# Create a site traces\n",
    "pvTrace = plotly.graph_objs.Scatter(\n",
    "    x = retrievedCoverFractions[:,0],\n",
    "    y = totalPVCover,\n",
    "    mode = 'markers',\n",
    "    name = 'PV Cover',\n",
    "    marker=dict(color='green',symbol='circle',opacity=0.5)\n",
    ")\n",
    "npvTrace = plotly.graph_objs.Scatter(\n",
    "    x = retrievedCoverFractions[:,1],\n",
    "    y = totalNPVCover,\n",
    "    mode = 'markers',\n",
    "    name = 'NPV Cover',\n",
    "    marker=dict(color='blue',symbol='circle',opacity=0.5)\n",
    ")\n",
    "bareTrace = plotly.graph_objs.Scatter(\n",
    "    x = retrievedCoverFractions[:,2],\n",
    "    y = totalBareCover,\n",
    "    mode = 'markers',\n",
    "    name = 'Bare Cover',\n",
    "    marker=dict(color='red',symbol='circle',opacity=0.5)\n",
    ")\n",
    "\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "data = [pvTrace,npvTrace,bareTrace]\n",
    "layout = plotly.graph_objs.Layout(\n",
    "    title='MPredicted vs Field Fractional Cover',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    xaxis=dict(\n",
    "        title='MODIS Fractional Cover',\n",
    "        ticklen=5,\n",
    "        zeroline=False,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Field Cover',\n",
    "        ticklen=5,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "plotFig = plotly.graph_objs.Figure(data=data, layout=layout)\n",
    "plotly.plotly.iplot(plotFig, filename='predict-plot')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and adjust outlying field sites\n",
    "------------------------------------\n",
    "This is a little helper script that finds the largest outlier in green or non-green with a matching  outlier with opposite sign, and adjusts the pint slightly. This is to account for observer bias that has been shown by Trevithick *etal* 2013 to affect green/non-green much more than bare. We run this twice, and select the number of itertations that minimised the unmixed bare RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum2oneWeight=numpy.array([0.25])\n",
    "rcond = 0.001\n",
    "\n",
    "# Test Inconsistent Field Data\n",
    "totalPVCoverEstimate = totalPVCover * 1.0\n",
    "totalNPVCoverEstimate =totalNPVCover * 1.0\n",
    "\n",
    "bareRMSerror=[]\n",
    "meanRMSerror=[]\n",
    "for i in range(189):\n",
    "\n",
    "    \n",
    "    endmembersWeighted=pinv2(numpy.dot(numpy.array([totalPVCoverEstimate,totalNPVCoverEstimate,totalBareCover]),pinv2(satelliteReflectanceTransformed.transpose(),rcond=rcond)))\n",
    "    endmembersWeightedSum=numpy.append(endmembersWeighted,numpy.array([sum2oneWeight.repeat(endmembersWeighted[0].size)]),axis=0)\n",
    "    \n",
    "        \n",
    "    def spectralUnmixing(spectra):\n",
    "        return nnls(endmembersWeightedSum,numpy.append(spectra,sum2oneWeight))[0]\n",
    "    \n",
    "    retrievedCoverFractions = numpy.apply_along_axis(spectralUnmixing,1,satelliteReflectanceTransformed)\n",
    "    \n",
    "    absError=(numpy.array([totalPVCoverEstimate,totalNPVCoverEstimate,totalBareCover]).transpose()-retrievedCoverFractions)\n",
    "        \n",
    "    rmsError=numpy.sqrt(((numpy.array([totalPVCoverEstimate,totalNPVCoverEstimate,totalBareCover]).transpose()-retrievedCoverFractions)**2).mean(axis=0))\n",
    "        \n",
    "    bareRMSerror=numpy.append(bareRMSerror,rmsError[2])\n",
    "    meanRMSerror=numpy.append(meanRMSerror,rmsError.mean())\n",
    "\n",
    "    \n",
    "    pvNpvError=numpy.abs(absError[:,0]-absError[:,1])\n",
    "    adjustSite=numpy.argmax(pvNpvError)\n",
    "    \n",
    "    if absError[adjustSite,0]>absError[adjustSite,1]:\n",
    "        totalPVCoverEstimate[adjustSite]=totalPVCoverEstimate[adjustSite]*0.9\n",
    "        totalNPVCoverEstimate[adjustSite]=1.0-(totalPVCoverEstimate[adjustSite]+totalBareCover[adjustSite])\n",
    "    else:\n",
    "        totalNPVCoverEstimate[adjustSite]=totalNPVCoverEstimate[adjustSite]*0.9\n",
    "        totalPVCoverEstimate[adjustSite]=1.0-(totalNPVCoverEstimate[adjustSite]+totalBareCover[adjustSite])\n",
    "\n",
    "\n",
    "print \"Optimal Adjustment is after %s iterations\" % numpy.argmin(bareRMSerror)\n",
    "\n",
    "\n",
    "# Create a Crossvalidation plot\n",
    "trace0 = plotly.graph_objs.Scatter(\n",
    "    x = numpy.linspace(0, bareRMSerror.size - 1),\n",
    "    y = bareRMSerror,\n",
    "    mode = 'lines',\n",
    "    name = 'Bare RMSE',\n",
    "    line = dict(color = ('rgb(22, 167, 96)'),width = 4))\n",
    "\n",
    "# Create a Crossvalidation plot\n",
    "trace1 = plotly.graph_objs.Scatter(\n",
    "    x = numpy.linspace(0, meanRMSerror.size - 1),\n",
    "    y = meanRMSerror,\n",
    "    mode = 'lines',\n",
    "    name = 'Mean RMSE',\n",
    "    line = dict(color = ('rgb(167, 22, 96)'),width = 4))\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "data = [trace0,trace1]\n",
    "plotly.plotly.iplot(data, filename='dodgy-Sites')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the final Unmixing RMSE and make a plot of the values \n",
    "--------------------------------------------------------------------\n",
    "This looks a little better after we adjust some of the (possibly) field misclassisied green/non-green points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optimal Endmember Test\n",
    "\n",
    "\n",
    "rmsError=numpy.sqrt(((numpy.array([totalPVCoverEstimate,totalNPVCoverEstimate,totalBareCover]).transpose()-retrievedCoverFractions)**2).mean(axis=0))\n",
    "print rmsError\n",
    "\n",
    "\n",
    "\n",
    "# Create a site traces\n",
    "pvTrace = plotly.graph_objs.Scatter(\n",
    "    x = retrievedCoverFractions[:,0],\n",
    "    y = totalPVCoverEstimate,\n",
    "    mode = 'markers',\n",
    "    name = 'PV Cover',\n",
    "    marker=dict(color='green',symbol='circle',opacity=0.75, size=3)\n",
    ")\n",
    "npvTrace = plotly.graph_objs.Scatter(\n",
    "    x = retrievedCoverFractions[:,1],\n",
    "    y = totalNPVCoverEstimate,\n",
    "    mode = 'markers',\n",
    "    name = 'NPV Cover',\n",
    "    marker=dict(color='blue',symbol='circle',opacity=0.5, size=3)\n",
    ")\n",
    "bareTrace = plotly.graph_objs.Scatter(\n",
    "    x = retrievedCoverFractions[:,2],\n",
    "    y = totalBareCover,\n",
    "    mode = 'markers',\n",
    "    name = 'Bare Cover',\n",
    "    marker=dict(color='red',symbol='circle',opacity=0.5, size=3)\n",
    ")\n",
    "\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "data = [pvTrace,npvTrace,bareTrace]\n",
    "layout = plotly.graph_objs.Layout(\n",
    "    title='Modis Predicted vs Field Fractional Cover',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    xaxis=dict(\n",
    "        title='MODIS Fractional Cover',\n",
    "        ticklen=5,\n",
    "        zeroline=False,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Field Cover',\n",
    "        ticklen=5,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "plotFig = plotly.graph_objs.Figure(data=data, layout=layout)\n",
    "plotly.plotly.iplot(plotFig, filename='predict-plot')\n",
    "\n",
    "\n",
    "# Save the final set of endmembers to a text file\n",
    "numpy.savetxt('endmembers.txt', endmembersWeighted.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
